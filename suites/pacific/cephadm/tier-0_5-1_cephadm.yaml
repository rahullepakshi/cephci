#===============================================================================================
#-------------------------------------
#----- Ceph code changes in 5.1 ------
#--------------------------------------
# * NFS deployment with pool and namespace is not supported.
#
#--------------------------------------
#
# Tier-0 test cases for
#    - Bootstrap
#    - Host management
#      - Add/Remove nodes
#      - SetAddress
#      - Attach/remove node labels
#    - Ceph role Service deployment with multiple options,
#    - Removal of services
#===============================================================================================
tests:
  - test:
      name: Install ceph pre-requisites
      desc: installation of ceph pre-requisites
      module: install_prereq.py
      abort-on-fail: true
  - test:
      name: Cephadm Bootstrap with custom dashboard credentials
      desc: Bootstrap with initial-dashboard user and password option
      module: test_bootstrap.py
      polarion-id: CEPH-83573719
      config:
        command: bootstrap
        base_cmd_args:
          verbose: true
        args:
          registry-url: registry.redhat.io
          custom_image: true
          mon-ip: "node1"
          orphan-initial-daemons: true
          skip-monitoring-stack: true
          initial-dashboard-user: admin123
          initial-dashboard-password: admin123
          fsid: f64f341c-655d-11eb-8778-fa163e914bcc
      destroy-cluster: false
      abort-on-fail: true
  - test:
      name: Add all hosts to ceph cluster
      desc: Add all host node with IP address and labels
      module: test_host.py
      polarion-id:
      config:
        service: host
        command: add_hosts
        args:
          nodes: []
          attach_ip_address: true
          labels: apply-all-labels
      destroy-cluster: false
      abort-on-fail: true
  - test:
      name: Apply Monitor with placement and limit
      desc: Apply monitor service with placement and limit
      module: test_mon.py
      abort-on-fail: true
      polarion-id: CEPH-83573778
      config:
        command: apply
        service: mon
        base_cmd_args:
          verbose: true
        args:
          placement:
            nodes:
                - node1
                - node2
                - node6
            limit: 3    # no of daemons
            sep: " "    # separator to be used for placements
  - test:
      name: Apply Monitor with host placement
      desc: Apply monitor with placement option on specified hosts
      module: test_mon.py
      abort-on-fail: true
      polarion-id: CEPH-83573732
      config:
        command: apply
        service: mon
        base_cmd_args:
          verbose: true
        args:
          placement:
            nodes:
                - node1
                - node2
                - node6
            sep: ";"
  - test:
      name: Apply Monitor using label
      desc: Apply monitor using label mon
      abort-on-fail: true
      module: test_mon.py
      polarion-id: CEPH-83573772
      config:
        command: apply
        service: mon
        base_cmd_args:
          verbose: true
        args:
          placement:
            label: mon
  - test:
      name: Apply Manager service
      desc: Apply manager service with placement option
      module: test_mgr.py
      polarion-id: CEPH-83573734
      config:
        command: apply
        service: mgr
        base_cmd_args:
          verbose: true
        args:
          placement:
            nodes:
              - node1
            sep: " "
      destroy-cluster: false
      abort-on-fail: true
  - test:
      name: Apply Manager service
      desc: Apply manager service with label option
      module: test_mgr.py
      polarion-id: CEPH-83573777
      config:
        command: apply
        service: mgr
        base_cmd_args:
          verbose: true
        args:
          placement:
            label: mgr
            sep: " "
      destroy-cluster: false
      abort-on-fail: true
  - test:
      name: Apply OSD Service
      desc: Apply OSD service with all available devices
      module: test_osd.py
      polarion-id: CEPH-83573735
      config:
        command: apply
        service: osd
        base_cmd_args:
          verbose: true
        args:
          all-available-devices: true
      destroy-cluster: false
      abort-on-fail: true
  - test:
      name: Configure client
      desc: Configure client on node9
      module: test_client.py
      polarion-id: CEPH-83573758
      config:
        command: add
        id: client.1                      # client Id (<type>.<Id>)
        node: node9                       # client node
        install_packages:
          - ceph-common                   # install ceph common packages
        copy_admin_keyring: true          # Copy admin keyring to node
        caps:                             # authorize client capabilities
          mon: "allow *"
          osd: "allow *"
          mds: "allow *"
          mgr: "allow *"
  - test:
      name: Remove client
      desc: remove client on node9
      module: test_client.py
      polarion-id: CEPH-83573759
      config:
        command: remove
        id: client.1                      # client Id (<type>.<Id>)
        node: node9                       # client node
        remove_packages:
          - ceph-common                   # Remove ceph common packages
        remove_admin_keyring: true        # Copy admin keyring to node
  - test:
      name: Add cephfs file system volume
      desc: Add file system for MDS service
      module: test_bootstrap.py
      polarion-id: CEPH-83574232
      config:
        command: shell
        args:          # arguments to ceph orch
          - ceph
          - fs
          - volume
          - create
          - cephfs
      destroy-cluster: false
      abort-on-fail: true
  - test:
      name: Apply MDS Service
      desc: Apply MDS service on all mds nodes
      module: test_mds.py
      polarion-id: CEPH-83573737
      config:
        command: apply
        service: mds
        base_cmd_args:          # arguments to ceph orch
          verbose: true
        pos_args:
          - cephfs              # name of the filesystem
        args:
          placement:
            nodes:
              - node2
              - node8
            limit: 2            # no of daemons
            sep: " "            # separator to be used for placements
      destroy-cluster: false
      abort-on-fail: true
  - test:
      name: Create replicated pool
      desc: Add pool for ISCSI service
      module: test_bootstrap.py
      polarion-id:
      config:
        command: shell
        args:             # command arguments
          - ceph
          - osd
          - pool
          - create
          - iscsi
          - "3"
          - "3"
          - replicated
      destroy-cluster: false
      abort-on-fail: true
  - test:
      name: Enable rbd application on pool
      desc: enable rbd on iscsi pool
      module: test_bootstrap.py
      polarion-id:
      config:
        command: shell
        args:             # command arguments
          - ceph
          - osd
          - pool
          - application
          - enable
          - iscsi
          - rbd
      destroy-cluster: false
      abort-on-fail: true
  - test:
      name: Apply ISCSI Service
      desc: Apply ISCSI target service on iscsi role nodes
      module: test_iscsi.py
      polarion-id: CEPH-83573756
      config:
        command: apply
        service: iscsi
        base_cmd_args:            # arguments to ceph orch
            verbose: true
        pos_args:
          - iscsi                 # name of the pool
          - api_user              # name of the API user
          - api_pass              # password of the api_user.
        args:
          trusted_ip_list:        #it can be used both as keyword/positional arg in 5.x
            - node1
            - node4
          placement:
            label: iscsi          # either label or node.
      destroy-cluster: false
      abort-on-fail: true
  - test:
      name: Apply ISCSI Service
      desc: Apply ISCSI target service on iscsi role nodes
      module: test_iscsi.py
      polarion-id:
      config:
        command: apply
        service: iscsi
        base_cmd_args:            # arguments to ceph orch
          verbose: true
        pos_args:
          - iscsi                 # name of the pool
          - api_user              # name of the API user
          - api_pass              # password of the api_user.
        args:
          trusted_ip_list:        #it can be used both as keyword/positional arg in 5.x
            - node1
            - node4
          placement:
            nodes:
              - node8          # either label or node.
      destroy-cluster: false
      abort-on-fail: true
  - test:
      name: Replace OSD daemon
      desc: Replace single OSD daemon from the cluster
      module: test_osd.py
      polarion-id: CEPH-83573766
      config:
        command: rm
        base_cmd_args:
          verbose: true
        pos_args:
          - 1
        args:
          - "--replace"
      destroy-cluster: false
      abort-on-fail: true
  - test:
      name: Add OSD
      desc: Add raw osd on node1
      module: test_daemon.py
      config:
        command: add
        service: osd
        pos_args:
          - "node1"
          - "/dev/vdb"
      destroy-cluster: false
      abort-on-fail: true
  - test:
      name: Apply Prometheus Service
      desc: Apply Prometheus service on role nodes
      module: test_monitoring.py
      polarion-id: CEPH-83573738
      config:
        command: apply
        service: prometheus
        base_cmd_args:          # arguments to ceph orch
          verbose: true
        args:
          placement:
            nodes:
              - node1
      destroy-cluster: false
      abort-on-fail: true
  - test:
      name: Apply Node-exporter Service
      desc: Apply Node-exporter service on role nodes
      module: test_monitoring.py
      polarion-id:
      config:
        command: apply
        service: node-exporter
        base_cmd_args:          # arguments to ceph orch
          verbose: true
        args:
          placement:
            nodes: "*"
      destroy-cluster: false
      abort-on-fail: true
  - test:
      name: Apply Alert-manager Service
      desc: Apply Alert-manager service on role nodes
      module: test_monitoring.py
      polarion-id:
      config:
        command: apply
        service: alertmanager
        base_cmd_args:          # arguments to ceph orch
          verbose: true
        args:
          placement:
            nodes:
              - node1
              - node2
      destroy-cluster: false
      abort-on-fail: true
  - test:
      name: Apply Grafana Service
      desc: Apply Grafana service on role nodes
      module: test_monitoring.py
      polarion-id:
      config:
        command: apply
        service: grafana
        base_cmd_args:          # arguments to ceph orch
          verbose: true
        args:
          placement:
            nodes:
              - node1
      destroy-cluster: false
      abort-on-fail: true
  - test:
      name: Apply collocated RGW Service
      desc: Apply collocated RGW service using node placements
      module: test_rgw.py
      polarion-id: CEPH-83573751
      config:
        command: apply
        service: rgw
        base_cmd_args:          # arguments to ceph orch
          verbose: true
        pos_args:               # positional arguments
          - foo                 # service id
        args:
          placement:
            count-per-host: 2
            nodes:              # A list of strings that would looked up
                - node6
                - node7
            sep: ";"            # separator to be used for placements
      destroy-cluster: false
      abort-on-fail: true
  - test:
      name: Apply collocated RGW Service
      desc: Apply collocated RGW service using label placement
      module: test_rgw.py
      polarion-id: CEPH-83574639
      config:
        command: apply
        service: rgw
        base_cmd_args:          # arguments to ceph orch
          verbose: true
        pos_args:               # positional arguments
          - foo                 # service id
        args:
          placement:
            count-per-host: 2
            label: rgw
      destroy-cluster: false
      abort-on-fail: true
  - test:
      name: Apply NFS Service
      desc: Apply NFS-Ganesha service on role nodes
      module: test_nfs.py
      polarion-id: CEPH-83573749
      config:
        command: apply
        service: nfs
        base_cmd_args:
          verbose: true
        args:
          svc_id: mynfs         # nfs service Id
          placement:
            nodes:
              - node8
              - node6
            limit: 2
            sep: ";"
      destroy-cluster: false
      abort-on-fail: true
  - test:
      name: Apply Crash Service
      desc: Apply Crash service on all nodes
      module: test_crash.py
      polarion-id:
      config:
        command: apply
        service: crash
        base_cmd_args:
            verbose: true
        args:
          placement:
            nodes: "*"
      destroy-cluster: false
      abort-on-fail: true
  - test:
      name: Remove NFS-Ganesha Service
      desc: Remove NFS-Ganesha service using orch remove option
      module: test_nfs.py
      polarion-id:
      config:
        command: remove
        service: nfs
        base_cmd_args:
          verbose: true
        args:
          service_name: nfs.mynfs
          verify: true
      destroy-cluster: false
      abort-on-fail: true
  - test:
      name: Remove RGW Service
      desc: Remove RGW service using orch remove option
      module: test_rgw.py
      polarion-id: CEPH-83573753
      config:
        command: remove
        service: rgw
        base_cmd_args:
          verbose: true
        args:
            service_name: rgw.foo
            verify: true
      destroy-cluster: false
      abort-on-fail: true
  - test:
      name: Remove ISCSI Service
      desc: Remove ISCSI service using orch remove option
      module: test_iscsi.py
      polarion-id: CEPH-83573757
      config:
        command: remove
        service: iscsi
        args:
            service_name: iscsi.iscsi
            verify: true
      destroy-cluster: false
      abort-on-fail: true
  - test:
      name: Remove Prometheus Service
      desc: Remove Prometheus service using orch remove option
      module: test_monitoring.py
      polarion-id:
      config:
        command: remove
        service: prometheus
        base_cmd_args:
          verbose: true
        args:
          service_name: prometheus
      destroy-cluster: false
      abort-on-fail: true
  - test:
      name: Remove Node-exporter Service
      desc: Remove Node-exporter service using orch remove option
      module: test_monitoring.py
      polarion-id:
      config:
        command: remove
        service: node-exporter
        args:
          service_name: node-exporter
      destroy-cluster: false
      abort-on-fail: true
  - test:
      name: Remove Alert-manager Service
      desc: Remove Alert-manager service using orch remove option
      module: test_monitoring.py
      polarion-id:
      config:
        command: remove
        service: alertmanager
        args:
          service_name: alertmanager
      destroy-cluster: false
      abort-on-fail: true
  - test:
      name: Remove Grafana Service
      desc: Remove Grafana service using orch remove option
      module: test_monitoring.py
      polarion-id:
      config:
        command: remove
        service: grafana
        args:
          service_name: grafana
      destroy-cluster: false
      abort-on-fail: true
  - test:
      name: Remove MDS Service
      desc: Remove MDS service using orch remove option
      module: test_mds.py
      polarion-id: CEPH-83573748
      config:
        command: remove
        service: mds
        base_cmd_args:
          verbose: true
        args:
          service_name: 'mds.cephfs'
      destroy-cluster: false
      abort-on-fail: true
  - test:
      name: set mon_allow_pool_delete
      desc: set mon_allow_pool_delete to true
      module: test_bootstrap.py
      polarion-id:
      config:
        command: shell
        args:
          - ceph
          - config
          - set
          - mon
          - mon_allow_pool_delete
          - "true"
      destroy-cluster: false
      abort-on-fail: true
  - test:
      name: remove cephfs file system volume
      desc: remove file system
      module: test_bootstrap.py
      polarion-id:
      config:
        command: shell
        args:
          - ceph
          - fs
          - volume
          - rm
          - cephfs
          - "--yes-i-really-mean-it"
      destroy-cluster: false
      abort-on-fail: true
  - test:
      name: Remove Crash Service
      desc: Remove Crash service using orch remove option
      module: test_crash.py
      polarion-id: CEPH-83573784
      config:
        command: remove
        service: crash
        base_cmd_args:
          verbose: true
        args:
          service_name: crash
      destroy-cluster: false
      abort-on-fail: true
